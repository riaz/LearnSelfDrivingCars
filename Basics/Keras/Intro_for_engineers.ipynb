{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras accepts 3 types of data\n",
    "\n",
    "1. Numpy array - if data fits in memory\n",
    "2. Tensorflow Dataset - useful for datasets that dont fit in memory\n",
    "    - useful for\n",
    "        - asynchronous preprocessing of data on CPU when GPU is busy and buffering to queue\n",
    "        - prefetching data on GPU so that its available immediately when the GPU is finished with previous batch\n",
    "3. Python generators - yeilds batch of data [custom subclasses of keras.utils.Sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has a lot of utility function to turn raw data into Dataset\n",
    "\n",
    "    - tf.keras.preprocessing.image_dataset_from_directory\n",
    "    - tf.keras.preprocessing.text_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 files belonging to 4 classes.\n",
      "(7, 200, 200, 3)\n",
      "<dtype: 'float32'>\n",
      "(7,)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "# example directory\n",
    "import os\n",
    "ex1_sample = os.path.join(BASE_DIR, \"sample_images\")\n",
    "ex1_dataset = keras.preprocessing.image_dataset_from_directory(ex1_sample, batch_size=64, image_size=(200,200))\n",
    "\n",
    "# lets iterate throught the dataset\n",
    "for data, label in ex1_dataset:\n",
    "    print(data.shape)\n",
    "    print(data.dtype)\n",
    "    print(label.shape)\n",
    "    print(label.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Keras preprocessing layers\n",
    "\n",
    "In Keras, you do in-model data preprocessing via preprocessing layers. This includes:\n",
    "\n",
    "Vectorizing raw strings of text via the TextVectorization layer\n",
    "Feature normalization via the Normalization layer\n",
    "Image rescaling, cropping, or image data augmentation\n",
    "The key advantage of using Keras preprocessing layers is that they can be included directly into your model, either during training or after training, which makes your models portable.\n",
    "\n",
    "Some preprocessing layers have a state:\n",
    "\n",
    "TextVectorization holds an index mapping words or tokens to integer indices\n",
    "Normalization holds the mean and variance of your features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 5 3 7 4]\n",
      " [2 5 3 6 4]], shape=(2, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "### turning strings into sequence of words\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "training_data = np.array([[\"This is the first sample\"],[\"This is the second sample\"]])\n",
    "\n",
    "# creating a text vectorization layer instance, and return integer token instances\n",
    "# or a dense token representation like a one-hot or TF-IDF\n",
    "vectorizer = TextVectorization(output_mode='int')\n",
    "\n",
    "# adapt method is used to generate a vocabulary\n",
    "vectorizer.adapt(training_data)\n",
    "\n",
    "# after calling adapt, the layer is able to encode any n-gram it has seen before \n",
    "# in the adapt method earlier\n",
    "\n",
    "integer_data = vectorizer(training_data)\n",
    "print(integer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0.]], shape=(2, 13), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### Converting strings to one-hot encoded bigrams\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "traning_data = np.array([[\"This is the first sample\"], [\"This is the second sample\"]])\n",
    "\n",
    "vectorizer = TextVectorization(output_mode='binary', ngrams=2)\n",
    "\n",
    "vectorizer.adapt(training_data)\n",
    "\n",
    "integer_data = vectorizer(training_data)\n",
    "print(integer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "training_data = np.random.randint(0,256, size=(64, 200, 200, 3)).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 200, 200, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalization(axis=1)\n",
    "normalizer.adapt(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 1.0000\n",
      "mean: -0.0000\n"
     ]
    }
   ],
   "source": [
    "normalized_data = normalizer(training_data)\n",
    "print(\"var: %.4f\" % np.var(normalized_data))\n",
    "print(\"mean: %.4f\" % np.mean(normalized_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling a center cropping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (64, 150, 150, 3)\n",
      "min:  0.0\n",
      "max:  1.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "training_data = np.random.randint(0, 256, size=(64,200,200,3)).astype(\"float32\")\n",
    "\n",
    "cropper = CenterCrop(height=150, width=150)\n",
    "scaler = Rescaling(scale=1.0 / 255)\n",
    "\n",
    "output_data = scaler(cropper(training_data)) # pipelined\n",
    "print(\"shape: \", output_data.shape)\n",
    "print(\"min: \", np.min(output_data))\n",
    "print(\"max: \", np.max(output_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building models with keras functional APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(None, None, 3)) # this will accept image of any size, 3 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = CenterCrop(height=150, width=150)(inputs)\n",
    "x = Rescaling(scale=1.0/255)(x)\n",
    "\n",
    "# Applying convolutions and max-polling\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x)\n",
    "\n",
    "# Applying global average pooling to get flat feature vectors\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Adding dense classifier on top\n",
    "num_classes = 10\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 200, 200, 3)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randint(0, 256, size=(64,200,200,3)).astype('float32')\n",
    "out_data = model(data)\n",
    "#### input_shape\n",
    "print(data.shape)\n",
    "#### output shape\n",
    "print(out_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing a summary of how the data is getting transformed down\n",
    "# this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "center_crop_3 (CenterCrop)   (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_3 (Rescaling)      (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 19,722\n",
      "Trainable params: 19,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understaing the above table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "The input is of shape (N*I*I*C)\n",
    "# Conv2D\n",
    "The next layer say conv2D - has K      - no of filters\n",
    "                                F      - filter or kernel size(FxF)\n",
    "                                S      - stride\n",
    "                                Pstart - start padding\n",
    "                                Pend   - end of padding\n",
    "                 Dimension of filter   - F * F * C\n",
    "        Output size of feature map(O)  - (I - F + Pstart + Pend)/S + 1\n",
    "                       Output Size     - OxOxK\n",
    "                    Number of params   - (F*F*C+1)*K\n",
    "                    \n",
    " \n",
    " # MaxPooling2D\n",
    "                     Output Size       - OxOxC\n",
    "                  Number of paramerts  - 0\n",
    "                  \n",
    "\n",
    "# FCN\n",
    "                         Output Size   - No_of_classes\n",
    "                       Num of params   - (Nin + 1)* Out Size\n",
    "     \n",
    "                                \n",
    "                               \n",
    "                               \n",
    "Note: 3 types of padding\n",
    "    1) Zero padding - Pstart == Pend == 0\n",
    "    2) Same padding - Pstart = S[I/S]-I+F-S/2\n",
    "                      Pend   = S[I/S]-I+F-S/2\n",
    "    3) Full padding   Pstart = [0, F-1]\n",
    "                      Pend = F-1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "First Conv(K=32, F=3, I =150, C = 3, P=0)\n",
    "    No.of params = (F*F*C+1)*K \n",
    "                 = (3*3*3+1)*32 = 896    -----------1\n",
    "        \n",
    "    Output(O) =  (150-3)+1 = 148        \n",
    "    Output Shape = OxOxK = 148*148*32\n",
    "\n",
    "MaxPool Layer1 (F=3, I = 148, C=32)\n",
    "    No of params = 0\n",
    "    Output (O) = floor[I/F] = 49\n",
    "    Output Shape = OxOxK = 49*49*32\n",
    "            \n",
    "\n",
    "Second Conv(K=32, F=3, I = 49, C=32, P=0)\n",
    "      No. of params = (F*F*C+1)*K = 9248   ----------2\n",
    "      Output(O) =  I - F + 2P/S +1 = (49-3)+1 = 47\n",
    "      Output Shape = 47*47*32\n",
    "      \n",
    "MaxPool Layer 2(F=3, I = 47, C=32)\n",
    "    No of params = 0\n",
    "    Output(O) = floor[I/F] = 15\n",
    "    Output Shape = 15*15*32 (O*O*C)\n",
    "    \n",
    "Third Conv(K=32, F=3, I=15, P=0, C =32)\n",
    "      No. of params = (F*F*C+1)*K = 9248    ----------3\n",
    "      Output(O) = (I - F  + 2P)/S +1 = (15-3)+1 = 13\n",
    "      Output Shape = 13*13*32\n",
    "      \n",
    "Global Average Pooling Layer will only - C dim (I=13, C=32)\n",
    "         No. of params = 0\n",
    "         Output Shape = 32 , (I is averaged)\n",
    "\n",
    "Dense   (I=32, O=10)\n",
    "        No. of params = (32+1)*10 = 330     -----------4\n",
    "        Output Shape = 10\n",
    "      \n",
    "      \n",
    "Total params = 896 + 2 * (9248) + 330 = 19,722 [trainable params (FC+CNN)] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have model and data, we will train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\n",
    "              keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "              loss=keras.losses.CategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once the model is compiled, we will try to fir the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(numpy_arrays_of_samples, \n",
    "          numpy_array_of_labels, \n",
    "          batch_size=32,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "rescaling_5 (Rescaling)      (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Fit on NumPy data\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2644\n",
      "Fit on Dataset\n",
      "Epoch 1/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.1154\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0774\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0559\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0411\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0308\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0255\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0215\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0199\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0203\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0140\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0161\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0108\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0129\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0118\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0083\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0135\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0081\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0083\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0099\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0075\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0087\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0093\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0076\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0089\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0069\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0063\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0063\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0085\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0037\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0083\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0067\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0089\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0077\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0060\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0038\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0051\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0058\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0074\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0032\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0047\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0089\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0041\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0033\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0081\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0049\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0047\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0051\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0064\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0052\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0046\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0044\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0068\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0045\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0023\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0047\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0063\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0043\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0042\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0028\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0043\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0063\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0034\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0060\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0040\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0032\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0060\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0013\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0025\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0069\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0044\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0038\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0048\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0039\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0029\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0045\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0027\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0043\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0044\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0025\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0049\n",
      "Epoch 81/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0052\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0030\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0023\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0061\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0038\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0037\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0034\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0037\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0026\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0046\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0033\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0028\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0025\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0036\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0053\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0025\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0043\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0031\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0022\n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0056\n"
     ]
    }
   ],
   "source": [
    "# Get the data as Numpy arrays\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Build a simple model\n",
    "inputs = keras.Input(shape=(28, 28))\n",
    "x = Rescaling(1.0 / 255)(inputs)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "# Train the model for 1 epoch from Numpy data\n",
    "batch_size = 64\n",
    "print(\"Fit on NumPy data\")\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1)\n",
    "\n",
    "# Train the model for 1 epoch using a dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "print(\"Fit on Dataset\")\n",
    "history = model.fit(dataset, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.11538337171077728, 0.07739068567752838, 0.05588624253869057, 0.041063304990530014, 0.030807601287961006, 0.025458209216594696, 0.02145235612988472, 0.01987391896545887, 0.02032712660729885, 0.014030501246452332, 0.016062753275036812, 0.010846823453903198, 0.012881933711469173, 0.011789713986217976, 0.00826964806765318, 0.01346042100340128, 0.008084124885499477, 0.008270231075584888, 0.009916430339217186, 0.007499664090573788, 0.00874023512005806, 0.009303811937570572, 0.0076078143902122974, 0.00893585104495287, 0.006909180898219347, 0.006265826988965273, 0.0063356682658195496, 0.008525144308805466, 0.0036899938713759184, 0.008277119137346745, 0.006698316428810358, 0.008872058242559433, 0.007671100553125143, 0.006016954779624939, 0.003829379566013813, 0.005144134163856506, 0.005758003797382116, 0.007364135235548019, 0.003244301537051797, 0.004738905001431704, 0.008858981542289257, 0.004137018695473671, 0.003344170982018113, 0.008132550865411758, 0.0048753139562904835, 0.004733922425657511, 0.005065707955509424, 0.006355931982398033, 0.00520517211407423, 0.004563671536743641, 0.004437866620719433, 0.006810528691858053, 0.0045153978280723095, 0.0022641385439783335, 0.004687880165874958, 0.006314330734312534, 0.004270518198609352, 0.004163480829447508, 0.0027630298864096403, 0.004291771911084652, 0.006261140573769808, 0.003360247239470482, 0.0060096438974142075, 0.0039746384136378765, 0.0031620885711163282, 0.0059594688937067986, 0.0013265775050967932, 0.0024860308039933443, 0.006855462212115526, 0.0044190664775669575, 0.003820332232862711, 0.004829352255910635, 0.0039034292567521334, 0.0028983154334127903, 0.004529239609837532, 0.002709008986130357, 0.004281522706151009, 0.004405975807458162, 0.0024567232467234135, 0.004854780621826649, 0.005190283991396427, 0.003024129429832101, 0.0023452220484614372, 0.006114496383816004, 0.0037623716052621603, 0.003669307567179203, 0.0034406096674501896, 0.003656940534710884, 0.002577051753178239, 0.0046495115384459496, 0.003338060574606061, 0.0027582156471908092, 0.002517105545848608, 0.0036276080645620823, 0.0052956268191337585, 0.0024903216399252415, 0.004313895478844643, 0.0031180833466351032, 0.0022406212519854307, 0.005647409241646528]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 3s 1ms/step - loss: 0.0041 - acc: 0.9994\n"
     ]
    }
   ],
   "source": [
    "#### Tracking performance metrics for the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "history = model.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing validation data to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.9967 - val_loss: 0.2466 - val_acc: 0.9966\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.9966 - val_loss: 0.2563 - val_acc: 0.9966\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.9967 - val_loss: 0.2327 - val_acc: 0.9966\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.9967 - val_loss: 0.2351 - val_acc: 0.9967\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.9967 - val_loss: 0.2660 - val_acc: 0.9967\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0076 - acc: 0.9967 - val_loss: 0.2623 - val_acc: 0.9967\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 5.5225e-04 - acc: 0.9967 - val_loss: 0.2404 - val_acc: 0.9967\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.9967 - val_loss: 0.2692 - val_acc: 0.9967\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0073 - acc: 0.9967 - val_loss: 0.2687 - val_acc: 0.9967\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.9967 - val_loss: 0.2552 - val_acc: 0.9967\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.9967 - val_loss: 0.2447 - val_acc: 0.9967\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.9967 - val_loss: 0.3052 - val_acc: 0.9967\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0063 - acc: 0.9967 - val_loss: 0.2567 - val_acc: 0.9967\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.9967 - val_loss: 0.2956 - val_acc: 0.9967\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.9967 - val_loss: 0.3053 - val_acc: 0.9967\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.9967 - val_loss: 0.2866 - val_acc: 0.9967\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.9967 - val_loss: 0.2719 - val_acc: 0.9967\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.9967 - val_loss: 0.2675 - val_acc: 0.9967\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.9967 - val_loss: 0.2674 - val_acc: 0.9967\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0035 - acc: 0.9967 - val_loss: 0.3239 - val_acc: 0.9967\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.9967 - val_loss: 0.3420 - val_acc: 0.9967\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0050 - acc: 0.9966 - val_loss: 0.2913 - val_acc: 0.9966\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.9966 - val_loss: 0.2629 - val_acc: 0.9966\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.9967 - val_loss: 0.2787 - val_acc: 0.9967\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.9966 - val_loss: 0.3340 - val_acc: 0.9966\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.9966 - val_loss: 0.2598 - val_acc: 0.9966\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0037 - acc: 0.9966 - val_loss: 0.2962 - val_acc: 0.9966\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.9966 - val_loss: 0.3175 - val_acc: 0.9966\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.9966 - val_loss: 0.2918 - val_acc: 0.9966\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.9966 - val_loss: 0.2661 - val_acc: 0.9967\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0046 - acc: 0.9967 - val_loss: 0.2795 - val_acc: 0.9967\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.9967 - val_loss: 0.3029 - val_acc: 0.9967\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0045 - acc: 0.9967 - val_loss: 0.3205 - val_acc: 0.9967\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0061 - acc: 0.9967 - val_loss: 0.2874 - val_acc: 0.9967\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.9967 - val_loss: 0.2879 - val_acc: 0.9967\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0019 - acc: 0.9967 - val_loss: 0.2995 - val_acc: 0.9967\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.9967 - val_loss: 0.3836 - val_acc: 0.9967\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.9967 - val_loss: 0.3176 - val_acc: 0.9967\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.9967 - val_loss: 0.3306 - val_acc: 0.9967\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.9967 - val_loss: 0.3580 - val_acc: 0.9967\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.9967 - val_loss: 0.3437 - val_acc: 0.9967\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.9967 - val_loss: 0.3044 - val_acc: 0.9967\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.9967 - val_loss: 0.3742 - val_acc: 0.9967\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0086 - acc: 0.9967 - val_loss: 0.3499 - val_acc: 0.9967\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.9967 - val_loss: 0.4163 - val_acc: 0.9967\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.9967 - val_loss: 0.3320 - val_acc: 0.9967\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0032 - acc: 0.9967 - val_loss: 0.3273 - val_acc: 0.9967\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.9967 - val_loss: 0.3351 - val_acc: 0.9967\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0034 - acc: 0.9967 - val_loss: 0.3198 - val_acc: 0.9967\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.9967 - val_loss: 0.3592 - val_acc: 0.9967\n"
     ]
    }
   ],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "history = model.fit(dataset, epochs=50, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss (val+train)')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Based on the above plot, looks like we need 4-fold cross validation\n",
    "since the validation set which is the test set, doesnt follow similar trend\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointing model training\n",
    "```\n",
    "Its important to checkpoint the training to recover from a long training job\n",
    "Also its important in a distributed training scenario, where workers fail\n",
    "\n",
    "Callbacks are a way to make model training entirely scriptable.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0036 - acc: 0.9967\n",
      "INFO:tensorflow:Assets written to: data/checkpoint/assets\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0025 - acc: 0.9967\n",
      "INFO:tensorflow:Assets written to: data/checkpoint/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb84cc2a370>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(BASE_DIR,\"checkpoint\"),\n",
    "        save_freq='epoch')\n",
    "]\n",
    "model.fit(dataset, epochs=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring real-time progress using tensorboard\n",
    "```\n",
    "We will use a callback to capture log and render on a real-time UI\n",
    "for model training updates - callend tensorboard\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0060 - acc: 0.9978\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.9978\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 8.5827e-04 - acc: 0.9978\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0020 - acc: 0.9978\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.9978\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0049 - acc: 0.9978\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 7.8186e-04 - acc: 0.9979\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.9979\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.9979\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.9979\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0012 - acc: 0.9979\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0026 - acc: 0.9979\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.9979\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.9979\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.9979\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0028 - acc: 0.9980\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0042 - acc: 0.9980\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0059 - acc: 0.9980\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0011 - acc: 0.9980\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0022 - acc: 0.9980\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0039 - acc: 0.9980\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0058 - acc: 0.9980\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0023 - acc: 0.9980\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.9980\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0015 - acc: 0.9980\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.9980\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0043 - acc: 0.9980\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.9981\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.9981\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0030 - acc: 0.9981\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 5.5096e-04 - acc: 0.9981\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0017 - acc: 0.9981\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0047 - acc: 0.9981\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0056 - acc: 0.9981\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0016 - acc: 0.9981\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.9982\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0024 - acc: 0.9982\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0029 - acc: 0.9982\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0033 - acc: 0.9982\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0013 - acc: 0.9982\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0053 - acc: 0.9982\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.9982\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0040 - acc: 0.9982\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0041 - acc: 0.9982\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 9.6638e-04 - acc: 0.9982\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0018 - acc: 0.9982\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0038 - acc: 0.9982\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0031 - acc: 0.9982\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0027 - acc: 0.9982\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0021 - acc: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb8691365e0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(dataset, epochs=50, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run this on terminal\n",
    "#!tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 793us/step - loss: 0.4749 - acc: 0.9982\n",
      "loss: 0.47\n",
      "acc: 1.00\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_dataset)  # returns loss and metrics\n",
    "print(\"loss: %.2f\" % loss)\n",
    "print(\"acc: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_dataset)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "  def train_step(self, data):\n",
    "    # Unpack the data. Its structure depends on your model and\n",
    "    # on what you pass to `fit()`.\n",
    "    x, y = data\n",
    "    with tf.GradientTape() as tape:\n",
    "      y_pred = self(x, training=True)  # Forward pass\n",
    "      # Compute the loss value\n",
    "      # (the loss function is configured in `compile()`)\n",
    "      loss = self.compiled_loss(y, y_pred,\n",
    "                                regularization_losses=self.losses)\n",
    "    # Compute gradients\n",
    "    trainable_vars = self.trainable_variables\n",
    "    gradients = tape.gradient(loss, trainable_vars)\n",
    "    # Update weights\n",
    "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "    # Update metrics (includes the metric that tracks the loss)\n",
    "    self.compiled_metrics.update_state(y, y_pred)\n",
    "    # Return a dict mapping metric names to current value\n",
    "    return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# Construct and compile an instance of CustomModel\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "# Just use `fit` as usual\n",
    "model.fit(dataset, epochs=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging your model with eager execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you write custom training steps or custom layers, you will need to debug them. The debugging experience is an integral part of a framework: with Keras, the debugging workflow is designed with the user in mind.\n",
    "\n",
    "By default, your Keras models are compiled to highly-optimized computation graphs that deliver fast execution times. That means that the Python code you write (e.g. in a custom train_step) is not the code you are actually executing. This introduces a layer of indirection that can make debugging hard.\n",
    "\n",
    "Debugging is best done step by step. You want to be able to sprinkle your code with print() statement to see what your data looks like after every operation, you want to be able to use pdb. You can achieve this by running your model eagerly. With eager execution, the Python code you write is the code that gets executed.\n",
    "\n",
    "Simply pass run_eagerly=True to compile():\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', run_eagerly=True)\n",
    "Of course, the downside is that it makes your model significantly slower. Make sure to switch it back off to get the benefits of compiled computation graphs once you are done debugging!\n",
    "\n",
    "In general, you will use run_eagerly=True every time you need to debug what's happening inside your fit() call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Pre-processing\n",
    "\n",
    "```\n",
    "Data processing happens in CPU and the GPU is good with feature normalization/data aug.\n",
    "\n",
    "Asynchronous multi-processing is useful to pre-fetch data to be fed to the gpu, while gpu is sill\n",
    "working on previous data, to keep gpu fully utilized\n",
    "\n",
    "In keras, we use dataset.map to achieve this\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.embedding_lookup), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'embedding/embeddings:0' shape=(10, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.tensordot), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'dense_7/kernel:0' shape=(32, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.bias_add), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'dense_7/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb84cb0bee0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example training data, of dtype `string`.\n",
    "samples = np.array([[\"This is the 1st sample.\"], [\"And here's the 2nd sample.\"]])\n",
    "labels = [[0], [1]]\n",
    "\n",
    "# Prepare a TextVectorization layer.\n",
    "vectorizer = TextVectorization(output_mode=\"int\")\n",
    "vectorizer.adapt(samples)\n",
    "\n",
    "# Asynchronous preprocessing: the text vectorization is part of the tf.data pipeline.\n",
    "# First, create a dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((samples, labels)).batch(2)\n",
    "# Apply text vectorization to the samples\n",
    "dataset = dataset.map(lambda x, y: (vectorizer(x), y))\n",
    "# Prefetch with a buffer size of 2 batches\n",
    "dataset = dataset.prefetch(2)\n",
    "\n",
    "# Our model should expect sequences of integers as inputs\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = layers.Embedding(input_dim=10, output_dim=32)(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", run_eagerly=True)\n",
    "model.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning - using Keras Tuner\n",
    "```\n",
    "First, place your model definition in a function, that takes a single hp argument.\n",
    "\n",
    "Inside this function, replace any value you want to tune with a call to hyperparameter sampling methods, e.g. hp.Int() or hp.Choice():\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    inputs = keras.Input(shape=(784,))\n",
    "    x = layers.Dense(\n",
    "        units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "        activation='relu')(inputs)\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function should return a compiled model.\n",
    "\n",
    "Next, instantiate a tuner object specifying your optimization objective and other search parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-7837513eff37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tuner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m tuner = keras_tuner.tuners.Hyperband(\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mallow_new_entries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_new_entries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         )\n\u001b[0;32m--> 367\u001b[0;31m         super(Hyperband, self).__init__(\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         )\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial)\u001b[0m\n\u001b[1;32m    109\u001b[0m             )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         super(Tuner, self).__init__(\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_populate_initial_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tuner_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# Update the recored scopes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-7178787165c9>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     x = layers.Dense(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'units'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         activation='relu')(inputs)\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             self.kernel, ids, weights, combiner='sum')\n\u001b[1;32m   1241\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMatMul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m     \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/util/tf_export.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m           \u001b[0;34m'Please pass these args as kwargs instead.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001b[0;32m--> 404\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5702\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5703\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5704\u001b[0;31m       return mat_mul_eager_fallback(\n\u001b[0m\u001b[1;32m   5705\u001b[0m           \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5706\u001b[0m           ctx=_ctx)\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul_eager_fallback\u001b[0;34m(a, b, transpose_a, transpose_b, name, ctx)\u001b[0m\n\u001b[1;32m   5737\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5738\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5739\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_inputs_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5740\u001b[0m   \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inputs_T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5741\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# not list allowed dtypes, in which case we should skip this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# dtype. This could be because we have an empty tensor and thus we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/omni/lib/python3.8/site-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;34m'Cannot convert a symbolic Keras input/output to a numpy array. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;34m'This error may indicate that you\\'re trying to pass a symbolic value '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model."
     ]
    }
   ],
   "source": [
    "import keras_tuner\n",
    "\n",
    "tuner = keras_tuner.tuners.Hyperband(\n",
    "  build_model,\n",
    "  objective='val_loss',\n",
    "  max_epochs=100,\n",
    "  executions_per_trial=2,\n",
    "  directory='my_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
